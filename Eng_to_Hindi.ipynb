{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T13:59:23.537519Z",
     "iopub.status.busy": "2021-09-20T13:59:23.537124Z",
     "iopub.status.idle": "2021-09-20T13:59:28.757457Z",
     "shell.execute_reply": "2021-09-20T13:59:28.756619Z",
     "shell.execute_reply.started": "2021-09-20T13:59:23.537437Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T13:59:59.069156Z",
     "iopub.status.busy": "2021-09-20T13:59:59.068744Z",
     "iopub.status.idle": "2021-09-20T13:59:59.073354Z",
     "shell.execute_reply": "2021-09-20T13:59:59.072271Z",
     "shell.execute_reply.started": "2021-09-20T13:59:59.069124Z"
    }
   },
   "outputs": [],
   "source": [
    "#Declaring some required variables\n",
    "ENCODER_LEN = 100\n",
    "DECODER_LEN = 100\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = BATCH_SIZE*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:04.909991Z",
     "iopub.status.busy": "2021-09-20T14:00:04.909672Z",
     "iopub.status.idle": "2021-09-20T14:00:06.010513Z",
     "shell.execute_reply": "2021-09-20T14:00:06.009693Z",
     "shell.execute_reply.started": "2021-09-20T14:00:04.909961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63241</th>\n",
       "      <td>Indian News Service - National News Agency</td>\n",
       "      <td>इण्डियन न्यूज सर्विस - राष्ट्रीय समाचार एजेंसी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81404</th>\n",
       "      <td>In West Bengal , it seems set to eat humble pi...</td>\n",
       "      <td>पश्चिम बंगाल में तो वह अपमान का घूंट पीने को भ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>One american dollar is equal to 60 pakistani r...</td>\n",
       "      <td>एक अमरीकी डालर की कीमत लगभग ६० पाकिस्तानी रुपय...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73434</th>\n",
       "      <td>but between those high highs,</td>\n",
       "      <td>लेकिन इन बेहतरीन लम्हों के बीच</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65711</th>\n",
       "      <td>Every other politician went along because when...</td>\n",
       "      <td>और वजह यह थी कि आर्थिक मामलं पर हमेशा विफल विच...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        english_sentence  \\\n",
       "63241         Indian News Service - National News Agency   \n",
       "81404  In West Bengal , it seems set to eat humble pi...   \n",
       "8803   One american dollar is equal to 60 pakistani r...   \n",
       "73434                      but between those high highs,   \n",
       "65711  Every other politician went along because when...   \n",
       "\n",
       "                                          hindi_sentence  \n",
       "63241     इण्डियन न्यूज सर्विस - राष्ट्रीय समाचार एजेंसी  \n",
       "81404  पश्चिम बंगाल में तो वह अपमान का घूंट पीने को भ...  \n",
       "8803   एक अमरीकी डालर की कीमत लगभग ६० पाकिस्तानी रुपय...  \n",
       "73434                     लेकिन इन बेहतरीन लम्हों के बीच  \n",
       "65711  और वजह यह थी कि आर्थिक मामलं पर हमेशा विफल विच...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataSet is taken from Kaggle\n",
    "\n",
    "train_df = pd.read_csv(\"Hindi_English_Truncated_Corpus.csv\")\n",
    "train_df.drop(['source'],axis=1,inplace=True)\n",
    "mask = (train_df['english_sentence'].str.len()>20) & (train_df['english_sentence'].str.len()<200)\n",
    "train_df = train_df.loc[mask]\n",
    "train_df = train_df.sample(64000, random_state=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:07.870544Z",
     "iopub.status.busy": "2021-09-20T14:00:07.870124Z",
     "iopub.status.idle": "2021-09-20T14:00:07.875751Z",
     "shell.execute_reply": "2021-09-20T14:00:07.874743Z",
     "shell.execute_reply.started": "2021-09-20T14:00:07.870510Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:11.345467Z",
     "iopub.status.busy": "2021-09-20T14:00:11.345121Z",
     "iopub.status.idle": "2021-09-20T14:00:11.445502Z",
     "shell.execute_reply": "2021-09-20T14:00:11.444654Z",
     "shell.execute_reply.started": "2021-09-20T14:00:11.345433Z"
    }
   },
   "outputs": [],
   "source": [
    "#Adding <SOS> and <END> tokens \n",
    "\n",
    "eng = train_df['english_sentence']\n",
    "hind = train_df['hindi_sentence']\n",
    "eng = eng.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
    "hind = hind.apply(lambda x: \"<SOS> \"+ x + \" <EOS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:12.863219Z",
     "iopub.status.busy": "2021-09-20T14:00:12.862898Z",
     "iopub.status.idle": "2021-09-20T14:00:19.055514Z",
     "shell.execute_reply": "2021-09-20T14:00:19.054651Z",
     "shell.execute_reply.started": "2021-09-20T14:00:12.863190Z"
    }
   },
   "outputs": [],
   "source": [
    "#Text Preprocessing for Model\n",
    "\n",
    "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
    "oov_token = '<unk>'\n",
    "eng_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters = filters, oov_token=oov_token)\n",
    "hind_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters = filters, oov_token=oov_token)\n",
    "eng_tokenizer.fit_on_texts(eng)\n",
    "hind_tokenizer.fit_on_texts(hind)\n",
    "inputs = eng_tokenizer.texts_to_sequences(eng)\n",
    "targets = hind_tokenizer.texts_to_sequences(hind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:19.057213Z",
     "iopub.status.busy": "2021-09-20T14:00:19.056871Z",
     "iopub.status.idle": "2021-09-20T14:00:19.065589Z",
     "shell.execute_reply": "2021-09-20T14:00:19.063477Z",
     "shell.execute_reply.started": "2021-09-20T14:00:19.057177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44305 51960\n"
     ]
    }
   ],
   "source": [
    "#Vocabulary size\n",
    "\n",
    "ENCODER_VOCAB = len(eng_tokenizer.word_index) + 1\n",
    "DECODER_VOCAB = len(hind_tokenizer.word_index) + 1\n",
    "print(ENCODER_VOCAB, DECODER_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:19.275458Z",
     "iopub.status.busy": "2021-09-20T14:00:19.275094Z",
     "iopub.status.idle": "2021-09-20T14:00:22.342130Z",
     "shell.execute_reply": "2021-09-20T14:00:22.341282Z",
     "shell.execute_reply.started": "2021-09-20T14:00:19.275423Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 08:02:07.077487: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Padding the inputs\n",
    "\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=ENCODER_LEN, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=DECODER_LEN, padding='post', truncating='post')\n",
    "inputs = tf.cast(inputs, dtype=tf.int64)\n",
    "targets = tf.cast(targets, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:22.343969Z",
     "iopub.status.busy": "2021-09-20T14:00:22.343633Z",
     "iopub.status.idle": "2021-09-20T14:00:22.436025Z",
     "shell.execute_reply": "2021-09-20T14:00:22.435169Z",
     "shell.execute_reply.started": "2021-09-20T14:00:22.343932Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:35.525499Z",
     "iopub.status.busy": "2021-09-20T14:00:35.525130Z",
     "iopub.status.idle": "2021-09-20T14:00:35.536890Z",
     "shell.execute_reply": "2021-09-20T14:00:35.535818Z",
     "shell.execute_reply.started": "2021-09-20T14:00:35.525465Z"
    }
   },
   "outputs": [],
   "source": [
    "#Code for Implementing Transformer Model\n",
    "\n",
    "\n",
    "def get_angles(position, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return position * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:36.442448Z",
     "iopub.status.busy": "2021-09-20T14:00:36.439861Z",
     "iopub.status.idle": "2021-09-20T14:00:36.460181Z",
     "shell.execute_reply": "2021-09-20T14:00:36.459327Z",
     "shell.execute_reply.started": "2021-09-20T14:00:36.442381Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:42.831716Z",
     "iopub.status.busy": "2021-09-20T14:00:42.831377Z",
     "iopub.status.idle": "2021-09-20T14:00:42.839448Z",
     "shell.execute_reply": "2021-09-20T14:00:42.838493Z",
     "shell.execute_reply.started": "2021-09-20T14:00:42.831685Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:43.579879Z",
     "iopub.status.busy": "2021-09-20T14:00:43.579534Z",
     "iopub.status.idle": "2021-09-20T14:00:43.589264Z",
     "shell.execute_reply": "2021-09-20T14:00:43.588265Z",
     "shell.execute_reply.started": "2021-09-20T14:00:43.579849Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:00:53.873347Z",
     "iopub.status.busy": "2021-09-20T14:00:53.873028Z",
     "iopub.status.idle": "2021-09-20T14:00:53.887505Z",
     "shell.execute_reply": "2021-09-20T14:00:53.886563Z",
     "shell.execute_reply.started": "2021-09-20T14:00:53.873311Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "        \n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        return x, attention_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:01:00.778006Z",
     "iopub.status.busy": "2021-09-20T14:01:00.777682Z",
     "iopub.status.idle": "2021-09-20T14:01:00.786163Z",
     "shell.execute_reply": "2021-09-20T14:01:00.785239Z",
     "shell.execute_reply.started": "2021-09-20T14:01:00.777975Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:01:08.715319Z",
     "iopub.status.busy": "2021-09-20T14:01:08.714972Z",
     "iopub.status.idle": "2021-09-20T14:01:08.720209Z",
     "shell.execute_reply": "2021-09-20T14:01:08.719234Z",
     "shell.execute_reply.started": "2021-09-20T14:01:08.715269Z"
    }
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:01:12.305266Z",
     "iopub.status.busy": "2021-09-20T14:01:12.304944Z",
     "iopub.status.idle": "2021-09-20T14:01:12.312036Z",
     "shell.execute_reply": "2021-09-20T14:01:12.310953Z",
     "shell.execute_reply.started": "2021-09-20T14:01:12.305234Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:01:15.931274Z",
     "iopub.status.busy": "2021-09-20T14:01:15.930931Z",
     "iopub.status.idle": "2021-09-20T14:01:15.937320Z",
     "shell.execute_reply": "2021-09-20T14:01:15.936337Z",
     "shell.execute_reply.started": "2021-09-20T14:01:15.931240Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:01:17.832107Z",
     "iopub.status.busy": "2021-09-20T14:01:17.831754Z",
     "iopub.status.idle": "2021-09-20T14:01:18.029889Z",
     "shell.execute_reply": "2021-09-20T14:01:18.028890Z",
     "shell.execute_reply.started": "2021-09-20T14:01:17.832076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:01:22.572711Z",
     "iopub.status.busy": "2021-09-20T14:01:22.572375Z",
     "iopub.status.idle": "2021-09-20T14:01:22.581467Z",
     "shell.execute_reply": "2021-09-20T14:01:22.579654Z",
     "shell.execute_reply.started": "2021-09-20T14:01:22.572681Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:01:26.648241Z",
     "iopub.status.busy": "2021-09-20T14:01:26.647928Z",
     "iopub.status.idle": "2021-09-20T14:01:26.671594Z",
     "shell.execute_reply": "2021-09-20T14:01:26.670844Z",
     "shell.execute_reply.started": "2021-09-20T14:01:26.648211Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:01:27.248191Z",
     "iopub.status.busy": "2021-09-20T14:01:27.247879Z",
     "iopub.status.idle": "2021-09-20T14:01:27.362127Z",
     "shell.execute_reply": "2021-09-20T14:01:27.361303Z",
     "shell.execute_reply.started": "2021-09-20T14:01:27.248161Z"
    }
   },
   "outputs": [],
   "source": [
    "#Defining the Transformer based model\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=ENCODER_VOCAB,\n",
    "    target_vocab_size=DECODER_VOCAB,\n",
    "    pe_input=1000,\n",
    "    pe_target=1000,\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:01:30.160263Z",
     "iopub.status.busy": "2021-09-20T14:01:30.159938Z",
     "iopub.status.idle": "2021-09-20T14:01:30.165790Z",
     "shell.execute_reply": "2021-09-20T14:01:30.164839Z",
     "shell.execute_reply.started": "2021-09-20T14:01:30.160233Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:01:35.731439Z",
     "iopub.status.busy": "2021-09-20T14:01:35.731100Z",
     "iopub.status.idle": "2021-09-20T14:01:35.737973Z",
     "shell.execute_reply": "2021-09-20T14:01:35.736764Z",
     "shell.execute_reply.started": "2021-09-20T14:01:35.731388Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            combined_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T14:02:00.162811Z",
     "iopub.status.busy": "2021-09-20T14:02:00.162479Z",
     "iopub.status.idle": "2021-09-20T15:12:41.629187Z",
     "shell.execute_reply": "2021-09-20T15:12:41.628375Z",
     "shell.execute_reply.started": "2021-09-20T14:02:00.162776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 10.8599 Accuracy 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mreset_states()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, (inp, tar)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        train_step(inp, tar)\n",
    "    \n",
    "        if batch % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "      \n",
    "    \n",
    "   \n",
    "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T15:13:54.245197Z",
     "iopub.status.busy": "2021-09-20T15:13:54.244875Z",
     "iopub.status.idle": "2021-09-20T15:13:54.252950Z",
     "shell.execute_reply": "2021-09-20T15:13:54.252113Z",
     "shell.execute_reply.started": "2021-09-20T15:13:54.245166Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets make predictions\n",
    "\n",
    "def evaluate(text):\n",
    "    text = eng_tokenizer.texts_to_sequences([text])\n",
    "    text = tf.keras.preprocessing.sequence.pad_sequences(text, maxlen=ENCODER_LEN, \n",
    "                                                                   padding='post', truncating='post')\n",
    "\n",
    "    encoder_input = tf.expand_dims(text[0], 0)\n",
    "\n",
    "    decoder_input = [hind_tokenizer.word_index['<sos>']]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(DECODER_LEN):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input, \n",
    "            output,\n",
    "            False,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predictions = predictions[: ,-1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        if predicted_id == hind_tokenizer.word_index['<eos>']:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T15:13:56.649071Z",
     "iopub.status.busy": "2021-09-20T15:13:56.648715Z",
     "iopub.status.idle": "2021-09-20T15:13:56.654009Z",
     "shell.execute_reply": "2021-09-20T15:13:56.652658Z",
     "shell.execute_reply.started": "2021-09-20T15:13:56.649041Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate(eng_text):\n",
    "    hind_text = evaluate(text=eng_text)[0].numpy()\n",
    "    hind_text = np.expand_dims(hind_text[1:], 0)  \n",
    "    return hind_tokenizer.sequences_to_texts(hind_text)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "Below are 2 translation predictions, the first one is on a sentence that was in the dataset and the other one that I wrote \n",
    "by myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T15:13:59.293212Z",
     "iopub.status.busy": "2021-09-20T15:13:59.292862Z",
     "iopub.status.idle": "2021-09-20T15:14:00.825980Z",
     "shell.execute_reply": "2021-09-20T15:14:00.825219Z",
     "shell.execute_reply.started": "2021-09-20T15:13:59.293179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मैं एक विद्यार्थी और अध्ययन के बारे में बहुत से था'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I am a student and I like to study very much.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T15:14:07.440345Z",
     "iopub.status.busy": "2021-09-20T15:14:07.440000Z",
     "iopub.status.idle": "2021-09-20T15:14:08.360153Z",
     "shell.execute_reply": "2021-09-20T15:14:08.359371Z",
     "shell.execute_reply.started": "2021-09-20T15:14:07.440304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मैं अपने परिवार के बारे में बहुत खुश हूं'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I am very happy about my family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T15:18:59.542014Z",
     "iopub.status.busy": "2021-09-20T15:18:59.541687Z",
     "iopub.status.idle": "2021-09-20T15:19:00.091206Z",
     "shell.execute_reply": "2021-09-20T15:19:00.090422Z",
     "shell.execute_reply.started": "2021-09-20T15:18:59.541985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मैं क्रिकेट खेलना चाहता हूँ'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I want to play cricket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T15:20:27.531184Z",
     "iopub.status.busy": "2021-09-20T15:20:27.530862Z",
     "iopub.status.idle": "2021-09-20T15:20:27.760748Z",
     "shell.execute_reply": "2021-09-20T15:20:27.759877Z",
     "shell.execute_reply.started": "2021-09-20T15:20:27.531154Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
